{"id":"../node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js","dependencies":[{"name":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js.map","includedInParent":true,"mtime":1733074798686},{"name":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/package.json","includedInParent":true,"mtime":1733076065657},{"name":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/package.json","includedInParent":true,"mtime":1733074798686},{"name":"@babel/runtime/helpers/interopRequireDefault","loc":{"line":3,"column":37,"index":52},"parent":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js","resolved":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/node_modules/@babel/runtime/helpers/interopRequireDefault.js"},{"name":"@babel/runtime/regenerator","loc":{"line":10,"column":50,"index":244},"parent":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js","resolved":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/node_modules/@babel/runtime/regenerator/index.js"},{"name":"@babel/runtime/helpers/asyncToGenerator","loc":{"line":12,"column":56,"index":333},"parent":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js","resolved":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/node_modules/@babel/runtime/helpers/asyncToGenerator.js"},{"name":"@babel/runtime/helpers/classCallCheck","loc":{"line":14,"column":54,"index":433},"parent":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js","resolved":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/node_modules/@babel/runtime/helpers/classCallCheck.js"},{"name":"@babel/runtime/helpers/createClass","loc":{"line":16,"column":51,"index":528},"parent":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/lib/SpeechServices/TextToSpeech/AudioContextConsumer.js","resolved":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/web-speech-cognitive-services/node_modules/@babel/runtime/helpers/createClass.js"}],"generated":{"js":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\n/* eslint no-await-in-loop: \"off\" */\nvar _default = /*#__PURE__*/function () {\n  function _default(audioContext) {\n    (0, _classCallCheck2.default)(this, _default);\n    this.audioContext = audioContext;\n  }\n\n  (0, _createClass2.default)(_default, [{\n    key: \"pause\",\n    value: function pause() {\n      this.audioContext && this.audioContext.suspend();\n      this.playingUtterance && this.playingUtterance.dispatchEvent(new CustomEvent('pause'));\n    }\n  }, {\n    key: \"resume\",\n    value: function resume() {\n      this.audioContext && this.audioContext.resume();\n      this.playingUtterance && this.playingUtterance.dispatchEvent(new CustomEvent('resume'));\n    }\n  }, {\n    key: \"start\",\n    value: function () {\n      var _start = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee(queue) {\n        var utterance;\n        return _regenerator.default.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!(utterance = queue.shift())) {\n                  _context.next = 7;\n                  break;\n                }\n\n                this.playingUtterance = utterance;\n                _context.next = 4;\n                return utterance.play(this.audioContext);\n\n              case 4:\n                this.playingUtterance = null;\n                _context.next = 0;\n                break;\n\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function start(_x) {\n        return _start.apply(this, arguments);\n      }\n\n      return start;\n    }()\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this.playingUtterance && this.playingUtterance.stop();\n\n      if (this.audioContext.state === 'suspended') {\n        // Play -> Pause -> Cancel (stop)\n        // This would generate these events: \"start\", \"pause\", \"end\"\n        // Without this code, the \"end\" event will not emit until resume() is called\n        // Cancelling an unstarted utterance will not emit any \"start\" or \"end\" event\n        this.audioContext.resume();\n      }\n    }\n  }]);\n  return _default;\n}();\n\nexports.default = _default;\n"},"sourceMaps":{"js":{"version":3,"file":"AudioContextConsumer.js","names":["audioContext","suspend","playingUtterance","dispatchEvent","CustomEvent","resume","queue","utterance","shift","play","stop","state"],"sources":["../../../src/SpeechServices/TextToSpeech/AudioContextConsumer.js"],"sourcesContent":["/* eslint no-await-in-loop: \"off\" */\n\nexport default class {\n  constructor(audioContext) {\n    this.audioContext = audioContext;\n  }\n\n  pause() {\n    this.audioContext && this.audioContext.suspend();\n    this.playingUtterance && this.playingUtterance.dispatchEvent(new CustomEvent('pause'));\n  }\n\n  resume() {\n    this.audioContext && this.audioContext.resume();\n    this.playingUtterance && this.playingUtterance.dispatchEvent(new CustomEvent('resume'));\n  }\n\n  async start(queue) {\n    let utterance;\n\n    while ((utterance = queue.shift())) {\n      this.playingUtterance = utterance;\n\n      await utterance.play(this.audioContext);\n\n      this.playingUtterance = null;\n    }\n  }\n\n  stop() {\n    this.playingUtterance && this.playingUtterance.stop();\n\n    if (this.audioContext.state === 'suspended') {\n      // Play -> Pause -> Cancel (stop)\n      // This would generate these events: \"start\", \"pause\", \"end\"\n\n      // Without this code, the \"end\" event will not emit until resume() is called\n      // Cancelling an unstarted utterance will not emit any \"start\" or \"end\" event\n      this.audioContext.resume();\n    }\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;AAAA;;EAGE,kBAAYA,YAAZ,EAA0B;IAAA;IACxB,KAAKA,YAAL,GAAoBA,YAApB;EACD;;;;WAED,iBAAQ;MACN,KAAKA,YAAL,IAAqB,KAAKA,YAAL,CAAkBC,OAAlB,EAArB;MACA,KAAKC,gBAAL,IAAyB,KAAKA,gBAAL,CAAsBC,aAAtB,CAAoC,IAAIC,WAAJ,CAAgB,OAAhB,CAApC,CAAzB;IACD;;;WAED,kBAAS;MACP,KAAKJ,YAAL,IAAqB,KAAKA,YAAL,CAAkBK,MAAlB,EAArB;MACA,KAAKH,gBAAL,IAAyB,KAAKA,gBAAL,CAAsBC,aAAtB,CAAoC,IAAIC,WAAJ,CAAgB,QAAhB,CAApC,CAAzB;IACD;;;;2FAED,iBAAYE,KAAZ;QAAA;QAAA;UAAA;YAAA;cAAA;gBAAA,MAGUC,SAAS,GAAGD,KAAK,CAACE,KAAN,EAHtB;kBAAA;kBAAA;gBAAA;;gBAII,KAAKN,gBAAL,GAAwBK,SAAxB;gBAJJ;gBAAA,OAMUA,SAAS,CAACE,IAAV,CAAe,KAAKT,YAApB,CANV;;cAAA;gBAQI,KAAKE,gBAAL,GAAwB,IAAxB;gBARJ;gBAAA;;cAAA;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,C;;;;;;;;;;WAYA,gBAAO;MACL,KAAKA,gBAAL,IAAyB,KAAKA,gBAAL,CAAsBQ,IAAtB,EAAzB;;MAEA,IAAI,KAAKV,YAAL,CAAkBW,KAAlB,KAA4B,WAAhC,EAA6C;QAC3C;QACA;QAEA;QACA;QACA,KAAKX,YAAL,CAAkBK,MAAlB;MACD;IACF"}},"error":null,"hash":"3f579f581eeac8219ed870a418a5daef","cacheData":{"env":{}}}