{"id":"../node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js","dependencies":[{"name":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js.map","includedInParent":true,"mtime":1733074701821},{"name":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/package.json","includedInParent":true,"mtime":1733076065657},{"name":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/microsoft-cognitiveservices-speech-sdk/package.json","includedInParent":true,"mtime":1733074701821},{"name":"../sdk/Exports","loc":{"line":6,"column":24,"index":232},"parent":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/SynthesisContext.js","resolved":"/Users/amblardv5/Nextcloud/2024/dialogue-systems-1-2024/node_modules/microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Exports.js"}],"generated":{"js":"\"use strict\";\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SynthesisContext = void 0;\nvar Exports_1 = require(\"../sdk/Exports\");\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nvar SynthesisContext = /** @class */ (function () {\n    function SynthesisContext(speechSynthesizer) {\n        this.privContext = {};\n        this.privSpeechSynthesizer = speechSynthesizer;\n    }\n    /**\n     * Adds a section to the synthesis.context object.\n     * @param sectionName Name of the section to add.\n     * @param value JSON serializable object that represents the value.\n     */\n    SynthesisContext.prototype.setSection = function (sectionName, value) {\n        this.privContext[sectionName] = value;\n    };\n    Object.defineProperty(SynthesisContext.prototype, \"audioOutputFormat\", {\n        /**\n         * Sets the audio output format for synthesis context generation.\n         * @param format {AudioOutputFormatImpl} the output format\n         */\n        set: function (format) {\n            this.privAudioOutputFormat = format;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    SynthesisContext.prototype.toJSON = function () {\n        var synthesisSection = this.buildSynthesisContext();\n        this.setSection(\"synthesis\", synthesisSection);\n        return JSON.stringify(this.privContext);\n    };\n    SynthesisContext.prototype.buildSynthesisContext = function () {\n        return {\n            audio: {\n                metadataOptions: {\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\n                    punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(Exports_1.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                    sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(Exports_1.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\n                    sessionEndEnabled: true,\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\n                    wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(Exports_1.PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\n                },\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\n            },\n            language: {\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n            }\n        };\n    };\n    return SynthesisContext;\n}());\nexports.SynthesisContext = SynthesisContext;\n\n\n"},"sourceMaps":{"js":{"version":3,"sources":["src/common.speech/SynthesisContext.ts"],"names":[],"mappings":";AAAA,4DAA4D;AAC5D,kCAAkC;;;AAGlC,0CAA+D;AAE/D;;;GAGG;AACH;IAKI,0BAAmB,iBAAoC;QAJ/C,gBAAW,GAA+B,EAAE,CAAC;QAKjD,IAAI,CAAC,qBAAqB,GAAG,iBAAiB,CAAC;IACnD,CAAC;IAED;;;;OAIG;IACI,qCAAU,GAAjB,UAAkB,WAAmB,EAAE,KAAsB;QACzD,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,GAAG,KAAK,CAAC;IAC1C,CAAC;IAMD,sBAAW,+CAAiB;QAJ5B;;;WAGG;aACH,UAA6B,MAA6B;YACtD,IAAI,CAAC,qBAAqB,GAAG,MAAM,CAAC;QACxC,CAAC;;;OAAA;IAEM,iCAAM,GAAb;QAEI,IAAM,gBAAgB,GAAsB,IAAI,CAAC,qBAAqB,EAAE,CAAC;QACzE,IAAI,CAAC,UAAU,CAAC,WAAW,EAAE,gBAAgB,CAAC,CAAC;QAE/C,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;IAC5C,CAAC;IAEO,gDAAqB,GAA7B;QACI,OAAO;YACH,KAAK,EAAE;gBACH,eAAe,EAAE;oBACb,eAAe,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,eAAe,CAAC;oBAC/D,0BAA0B,EAAE,IAAI,CAAC,qBAAqB,CAAC,UAAU,CAAC,WAAW,CACzE,oBAAU,CAAC,gDAAgD,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,YAAY,CAAC,CAAC;oBAC7G,uBAAuB,EAAE,IAAI,CAAC,qBAAqB,CAAC,UAAU,CAAC,WAAW,CACtE,oBAAU,CAAC,6CAA6C,EAAE,KAAK,CAAC;oBACpE,iBAAiB,EAAE,IAAI;oBACvB,aAAa,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,cAAc,CAAC;oBAC5D,mBAAmB,EAAE,IAAI,CAAC,qBAAqB,CAAC,UAAU,CAAC,WAAW,CAClE,oBAAU,CAAC,yCAAyC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,qBAAqB,CAAC,YAAY,CAAC,CAAC;iBACzG;gBACD,YAAY,EAAE,IAAI,CAAC,qBAAqB,CAAC,wBAAwB;aACpE;YACD,QAAQ,EAAE;gBACN,aAAa,EAAE,IAAI,CAAC,qBAAqB,CAAC,wBAAwB;aACrE;SACiB,CAAC;IAC3B,CAAC;IACL,uBAAC;AAAD,CAvDA,AAuDC,IAAA;AAvDY,4CAAgB","file":"SynthesisContext.js","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\r\n// Licensed under the MIT license.\r\n\r\nimport { AudioOutputFormatImpl } from \"../sdk/Audio/AudioOutputFormat\";\r\nimport { PropertyId, SpeechSynthesizer } from \"../sdk/Exports\";\r\n\r\n/**\r\n * Represents the JSON used in the synthesis.context message sent to the speech service.\r\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\r\n */\r\nexport class SynthesisContext {\r\n    private privContext: { [section: string]: any } = {};\r\n    private privSpeechSynthesizer: SpeechSynthesizer;\r\n    private privAudioOutputFormat: AudioOutputFormatImpl;\r\n\r\n    public constructor(speechSynthesizer: SpeechSynthesizer) {\r\n        this.privSpeechSynthesizer = speechSynthesizer;\r\n    }\r\n\r\n    /**\r\n     * Adds a section to the synthesis.context object.\r\n     * @param sectionName Name of the section to add.\r\n     * @param value JSON serializable object that represents the value.\r\n     */\r\n    public setSection(sectionName: string, value: string | object): void {\r\n        this.privContext[sectionName] = value;\r\n    }\r\n\r\n    /**\r\n     * Sets the audio output format for synthesis context generation.\r\n     * @param format {AudioOutputFormatImpl} the output format\r\n     */\r\n    public set audioOutputFormat(format: AudioOutputFormatImpl) {\r\n        this.privAudioOutputFormat = format;\r\n    }\r\n\r\n    public toJSON(): string {\r\n\r\n        const synthesisSection: ISynthesisSection = this.buildSynthesisContext();\r\n        this.setSection(\"synthesis\", synthesisSection);\r\n\r\n        return JSON.stringify(this.privContext);\r\n    }\r\n\r\n    private buildSynthesisContext(): ISynthesisSection {\r\n        return {\r\n            audio: {\r\n                metadataOptions: {\r\n                    bookmarkEnabled: (!!this.privSpeechSynthesizer.bookmarkReached),\r\n                    punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\r\n                        PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\r\n                    sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\r\n                        PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\r\n                    sessionEndEnabled: true,\r\n                    visemeEnabled: (!!this.privSpeechSynthesizer.visemeReceived),\r\n                    wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(\r\n                        PropertyId.SpeechServiceResponse_RequestWordBoundary, (!!this.privSpeechSynthesizer.wordBoundary)),\r\n                },\r\n                outputFormat: this.privAudioOutputFormat.requestAudioFormatString,\r\n            },\r\n            language: {\r\n                autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\r\n            }\r\n        } as ISynthesisSection;\r\n    }\r\n}\r\n\r\ninterface ISynthesisSection {\r\n    audio: {\r\n        outputFormat: string;\r\n        metadataOptions: {\r\n            bookmarkEnabled: boolean;\r\n            wordBoundaryEnabled: string;\r\n            punctuationBoundaryEnabled: string;\r\n            visemeEnabled: boolean;\r\n            sentenceBoundaryEnabled: string;\r\n            sessionEndEnabled: boolean;\r\n        };\r\n    };\r\n    language: {\r\n        autoDetection: boolean;\r\n    };\r\n}\r\n"]}},"error":null,"hash":"b2a36db21d5b1ac8ac1d8b654858bfd6","cacheData":{"env":{}}}